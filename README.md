# Fine-Tuning DistilBERT pour la Classification des √âmotions

Ce projet montre comment fine-tuner le mod√®le **DistilBERT** sur le dataset **dair-ai/emotion** afin de classifier des textes selon 6 √©motions :  
**anger, fear, joy, love, sadness, surprise**.

Le projet est enti√®rement d√©velopp√© sur **Google Colab** avec GPU, en utilisant les biblioth√®ques HuggingFace (`transformers`, `datasets`) et PyTorch.

---

## üìå Objectifs
- Charger et explorer un dataset NLP
- Tokenizer les textes avec DistilBERT
- Encoder les donn√©es et pr√©parer les tenseurs
- Entra√Æner un mod√®le Transformer avec *fine-tuning*
- √âvaluer les performances (Accuracy, F1-score)
- Tester le mod√®le sur des phrases personnalis√©es

---
