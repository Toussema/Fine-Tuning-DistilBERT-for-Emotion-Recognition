# Fine-Tuning-DistilBERT-for-Emotion-Recognition
Ce projet présente un pipeline complet de fine-tuning d’un modèle NLP pré-entraîné utilisant la bibliothèque HuggingFace Transformers. L’objectif est de prendre un modèle existant (DistilBERT), puis de le spécialiser sur un dataset ciblé pour améliorer ses performances sur une tâche spécifique (classification d’émotions).
