{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60824a46",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U datasets\n",
    "!pip install -U bertviz\n",
    "!pip install -U umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab159b4",
   "metadata": {},
   "source": [
    "*Data Exploration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3232b7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "emotion = load_dataset(\"dair-ai/emotion\")\n",
    "print(emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d65ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "emotion.set_format(type='pandas')\n",
    "\n",
    "df = emotion['train'][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9be70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "classes = emotion['train'].features['label'].names\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6292b2",
   "metadata": {},
   "source": [
    "Dataset Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5ff10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "label_counts = df['label_name'].value_counts(ascending=True)\n",
    "label_counts.plot.barh()\n",
    "plt.title('Frequency of Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4ad34",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['Words Per Tweet'] = df['text'].str.split().apply(len)\n",
    "df.boxplot(\"Words Per Tweet\", by='label_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a267cdd1",
   "metadata": {},
   "source": [
    "**Text to Tokens Conversion**\n",
    "\n",
    "Transformer models like DistilBERT cannot receive raw strings as input; instead, they assume the text has been tokenized and encoded as numerical vectors.\n",
    "\n",
    "Tokenization is the step of breaking down a string into the atomic units used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e8a95",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2a8cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text = \"I love Machine Learning!. Tokenization is awesome\"\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c27e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c475e68",
   "metadata": {},
   "source": [
    "*Tokenization of the Emotion Data*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6dd37e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "emotion.reset_format()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc40238",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# map() method would be used\n",
    "\n",
    "def tokenize(batch):\n",
    "  temp =tokenizer(batch['text'], padding=True, truncation=True)\n",
    "  return temp\n",
    "\n",
    "print(tokenize(emotion[\"train\"][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65cc5ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "emotions_encoded = emotion.map(tokenize, batched=True, batch_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0791a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "emotions_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00a2ea",
   "metadata": {},
   "source": [
    "*Model Building*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833d5a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e887b2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114b60f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79598d59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754029b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e12a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "last_hidden_states.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77679010",
   "metadata": {},
   "source": [
    "*Fine-Tuning Transformers*\n",
    "\n",
    "AutoModelForSequenceClassification model has a classification head on top of the pretrained model outputs\n",
    "* The first thing we need is a pretrained DistilBERT model like the one we used in the feature-based approach.\n",
    "* The only slight modification is that we use the AutoModelForSequenceClassification model instead of AutoModel.\n",
    "* The difference is that the AutoModelForSequenceClassification model has a classification head on top of the pretrained model outputs, which can be easily trained with the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33334c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = len(classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels = num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10924598",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8e467",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc33c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148d9ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036643b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "model_name = \"distilbert-finetuned-emotion\"\n",
    "\n",
    "training_args = TrainingArguments(output_dir = model_name,\n",
    "                                 num_train_epochs=2,\n",
    "                                 learning_rate = 2e-5,\n",
    "                                 per_device_train_batch_size= batch_size,\n",
    "                                 per_device_eval_batch_size = batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  eval_strategy = 'epoch',\n",
    "                                  disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8668332",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  f1 = f1_score(labels, preds, average='weighted')\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\"accuracy\": acc, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255a2ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=emotions_encoded['train'],\n",
    "                  eval_dataset=emotions_encoded['validation'],\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df4894",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0ff52",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "preds_outputs = trainer.predict(emotions_encoded['test'])\n",
    "preds_outputs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33252b88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_preds = np.argmax(preds_outputs.predictions, axis=1)\n",
    "y_true = emotions_encoded['test'][:]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f87fc9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classes)\n",
    "print(classification_report(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00ef25",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be08ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text = 'i want to kill you'\n",
    "input_encoded = tokenizer(text, return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "  outputs = model(**input_encoded)\n",
    "\n",
    "logits = outputs.logits\n",
    "pred = torch.argmax(logits, dim=1).item()\n",
    "pred, classes[pred]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
